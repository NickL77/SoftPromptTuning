{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments\n",
    "from trl import SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from banking_77_constants import banking77_label_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "model_name = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Llama reserverd special tokens and IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_token_strs, prefix_token_ids = [], []\n",
    "\n",
    "# llama reserved 250 special tokens\n",
    "for i in range(251):\n",
    "    prefix_token_strs.append(f\"<|reserved_special_token_{i}|>\")\n",
    "\n",
    "prefix_token_ids = tokenizer.convert_tokens_to_ids(prefix_token_strs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to map numerical labels to string labels\n",
    "def map_labels(example):\n",
    "    # Map the numerical label to the string label\n",
    "    example['label_str'] = banking77_label_map[example['label']]\n",
    "    return example\n",
    "\n",
    "# Load the PolyAI/banking77 dataset\n",
    "dataset = load_dataset(\"PolyAI/banking77\")\n",
    "\n",
    "# Access the training set\n",
    "train_dataset = dataset[\"train\"]\n",
    "test_dataset = dataset[\"test\"]\n",
    "\n",
    "# Apply the function to the dataset\n",
    "train_dataset = train_dataset.map(map_labels)\n",
    "test_dataset = test_dataset.map(map_labels)\n",
    "\n",
    "train_dataset = train_dataset.shuffle(seed=42)\n",
    "test_dataset = test_dataset.shuffle(seed=42)\n",
    "\n",
    "# Check the updated dataset\n",
    "train_dataset[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the classes part first, while allowing to add the user query in later\n",
    "prompt_template = \\\n",
    "\"\"\"## Instructions\n",
    "Classify the provided piece of text into one of the predefined classes.\n",
    "\n",
    "## Classes\n",
    "{classes}\n",
    "\n",
    "## Output Format\n",
    "Provide your answer in <answer></answer> XML tags. Output the xml tags and answer only.\n",
    "\n",
    "## Input Text\n",
    "{{text}}\n",
    "\n",
    "## Answer\"\"\".format(classes=\"\\n\".join(banking77_label_map.values()))\n",
    "\n",
    "# Uncomment below to view prompt\n",
    "# print(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define an answer parser that extracts the answer based on the format the prompt tempalte defines\n",
    "def parse_value_from_xml_with_regex(xml_string, tag_name):\n",
    "    \n",
    "    pattern = f'<{tag_name}>(.*?)</{tag_name}>'\n",
    "    match = re.search(pattern, xml_string, re.DOTALL)  # re.DOTALL allows matching across multiple lines\n",
    "    \n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "assert parse_value_from_xml_with_regex(\"<answer>foo</answer>\", \"answer\") == \"foo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create test dataset with prompt template\n",
    "This is the baseline dataset so we will not add a soft prefix prompt. See below for when we add the prefix tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_messages(row):\n",
    "    return {\"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt_template.format(text=row[\"text\"])}\n",
    "    ]}\n",
    "\n",
    "test_dataset_no_prefix = test_dataset.map(create_test_messages)\n",
    "\n",
    "test_dataset_no_prefix[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running non-finetuned model on just 1 row, change i as desired\n",
    "\n",
    "i = 0\n",
    "user_query = test_dataset_no_prefix[i][\"text\"]\n",
    "messages = test_dataset_no_prefix[i][\"messages\"]\n",
    "golden_answer = test_dataset_no_prefix[i][\"label_str\"]\n",
    "\n",
    "input_ids = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\",\n",
    ").to(model.device)\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=32,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.001,\n",
    "    top_p=0,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "\n",
    "response = outputs[0][input_ids.shape[-1]:]\n",
    "uncleaned_response = tokenizer.decode(response, skip_special_tokens=False)\n",
    "parsed_answer = parse_value_from_xml_with_regex(tokenizer.decode(response, skip_special_tokens=True), \"answer\")\n",
    "\n",
    "print(\"User query:\")\n",
    "print(user_query)\n",
    "print()\n",
    "print(\"Model response (with special tokens):\")\n",
    "print(uncleaned_response)\n",
    "print()\n",
    "print(\"Parsed model response (without tokens):\")\n",
    "print(parsed_answer)\n",
    "print()\n",
    "print(\"Correct answer:\")\n",
    "print(golden_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Running on sample of test dataset. We're only using the first 300 rows in this case\n",
    "\n",
    "pred_ls, golden_ls = [], []\n",
    "num_correct, num_total = 0, 0\n",
    "\n",
    "# for i in tqdm(range(len(test_dataset_no_prefix))):\n",
    "for i in tqdm(range(300)):\n",
    "    messages = test_dataset_no_prefix[i][\"messages\"]\n",
    "\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(model.device)\n",
    "\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        max_new_tokens=128,\n",
    "        eos_token_id=terminators,\n",
    "        do_sample=True,\n",
    "        temperature=0.001,\n",
    "        top_p=0,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "\n",
    "    response = outputs[0][input_ids.shape[-1]:]\n",
    "    response = tokenizer.decode(response, skip_special_tokens=False)\n",
    "    pred = parse_value_from_xml_with_regex(response, \"answer\")\n",
    "    \n",
    "    pred_ls.append(pred)\n",
    "    golden_ls.append(test_dataset_no_prefix[i][\"label_str\"])\n",
    "\n",
    "    if pred == test_dataset_no_prefix[i][\"label_str\"]:\n",
    "        num_correct += 1\n",
    "    num_total += 1\n",
    "\n",
    "accuracy = num_correct / num_total\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting hyperparameters\n",
    "\n",
    "NUM_SPECIAL_TOKENS_IN_PREFIX = 32\n",
    "LEARNING_RATE = 2e-4\n",
    "BATCH_SIZE = 4\n",
    "WARMUP_RATIO = 0.1\n",
    "WEIGHT_DECAY = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prefix will be comprised of n special tokens \n",
    "prefix = \"\".join(prefix_token_strs[:NUM_SPECIAL_TOKENS_IN_PREFIX])\n",
    "\n",
    "# We create a training dataset that includes the answer\n",
    "# We also create another test dataset, this time with the prefix for the finetuned model\n",
    "\n",
    "def create_prefix_messages(row):\n",
    "    return {\"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prefix + prompt_template.format(text=row[\"text\"])},\n",
    "        {\"role\": \"assistant\", \"content\": \"<answer>\" + row[\"label_str\"] + \"</answer>\"}\n",
    "    ]}\n",
    "\n",
    "def create_prefix_messages_no_answer(row):\n",
    "    return {\"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prefix + prompt_template.format(text=row[\"text\"])}\n",
    "    ]}\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map(create_prefix_messages)\n",
    "test_dataset_with_prefix = test_dataset.map(create_prefix_messages_no_answer)\n",
    "\n",
    "train_dataset[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all parameters except the embedding layer\n",
    "# Add the hook to zero out non-special token gradients\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.get_input_embeddings().weight.requires_grad = True\n",
    "\n",
    "embeddings_to_update = torch.tensor(prefix_token_ids[:NUM_SPECIAL_TOKENS_IN_PREFIX], dtype=torch.long)\n",
    "\n",
    "# Ensure embeddings_to_update is on the correct device\n",
    "embeddings_to_update = embeddings_to_update.to(model.device)\n",
    "\n",
    "def grad_hook(grad):\n",
    "    mask = torch.zeros_like(grad)\n",
    "    mask[embeddings_to_update] = 1.0\n",
    "    \n",
    "    masked_grad = grad * mask\n",
    "    return masked_grad\n",
    "\n",
    "hook_handle = model.get_input_embeddings().weight.register_hook(grad_hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only train on completion tokens\n",
    "response_template = \"<|start_header_id|>assistant<|end_header_id|>\"\n",
    "collator = DataCollatorForCompletionOnlyLM(response_template, tokenizer=tokenizer)\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model,\n",
    "    train_dataset=train_dataset,\n",
    "    data_collator=collator,\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = BATCH_SIZE,\n",
    "        gradient_accumulation_steps = 1,\n",
    "        warmup_ratio = WARMUP_RATIO,\n",
    "        num_train_epochs = 1, # Set this for 1 full training run.\n",
    "        learning_rate = LEARNING_RATE,\n",
    "        fp16 = False, # switch these depending if you're GPU supports BF16\n",
    "        bf16 = True,\n",
    "        logging_steps = 16,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = WEIGHT_DECAY,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        gradient_checkpointing=True\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "hook_handle.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running on sample of test dataset; this time with the newly trained prefix\n",
    "\n",
    "pred_ls, golden_ls = [], []\n",
    "num_correct, num_total = 0, 0\n",
    "\n",
    "# for i in tqdm(range(len(test_dataset_no_prefix))):\n",
    "for i in tqdm(range(300)):\n",
    "    messages = test_dataset_with_prefix[i][\"messages\"]\n",
    "\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(model.device)\n",
    "\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        max_new_tokens=128,\n",
    "        eos_token_id=terminators,\n",
    "        do_sample=True,\n",
    "        temperature=0.001,\n",
    "        top_p=0,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "\n",
    "    response = outputs[0][input_ids.shape[-1]:]\n",
    "    response = tokenizer.decode(response, skip_special_tokens=False)\n",
    "    pred = parse_value_from_xml_with_regex(response, \"answer\")\n",
    "    \n",
    "    pred_ls.append(pred)\n",
    "    golden_ls.append(test_dataset_no_prefix[i][\"label_str\"])\n",
    "\n",
    "    if pred == test_dataset_no_prefix[i][\"label_str\"]:\n",
    "        num_correct += 1\n",
    "    num_total += 1\n",
    "\n",
    "accuracy = num_correct / num_total\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Benchmarks\n",
    "\n",
    "| Num Prefix Tokens | 16    | 32    | 64    |\n",
    "| :---------------- | :---: | :---: | :---: |\n",
    "| Llama 3B          | 0.79  | 0.83  | 0.8266|\n",
    "| Llama 1B          | 0.6466| 0.6766| 0.7333|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirming that non-prefix weights have not been changed by running no prefix dataset again\n",
    "\n",
    "pred_ls, golden_ls = [], []\n",
    "num_correct, num_total = 0, 0\n",
    "\n",
    "# for i in tqdm(range(len(test_dataset_no_prefix))):\n",
    "for i in tqdm(range(300)):\n",
    "    messages = test_dataset_no_prefix[i][\"messages\"]\n",
    "\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(model.device)\n",
    "\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        max_new_tokens=128,\n",
    "        eos_token_id=terminators,\n",
    "        do_sample=True,\n",
    "        temperature=0.001,\n",
    "        top_p=0,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "\n",
    "    response = outputs[0][input_ids.shape[-1]:]\n",
    "    response = tokenizer.decode(response, skip_special_tokens=False)\n",
    "    pred = parse_value_from_xml_with_regex(response, \"answer\")\n",
    "    \n",
    "    pred_ls.append(pred)\n",
    "    golden_ls.append(test_dataset_no_prefix[i][\"label_str\"])\n",
    "\n",
    "    if pred == test_dataset_no_prefix[i][\"label_str\"]:\n",
    "        num_correct += 1\n",
    "    num_total += 1\n",
    "\n",
    "accuracy = num_correct / num_total\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
